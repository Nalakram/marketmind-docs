import abc
import pandas as pd
from _typeshed import Incomplete
from abc import ABC, abstractmethod
from srcPy.utils.exceptions import DataFetchError as DataFetchError
from srcPy.utils.logger import get_logger as get_logger

logger: Incomplete
FETCH_FAILURES: Incomplete
FETCH_SUCCESSES: Incomplete
FETCH_DURATION: Incomplete

class DataSource(ABC, metaclass=abc.ABCMeta):
    @abstractmethod
    def get_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame: ...
    @abstractmethod
    async def get_realtime(self, symbol: str) -> float: ...

class AlphaVantageSource(DataSource):
    api_key: Incomplete
    base_url: str
    def __init__(self, config) -> None: ...
    def get_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame: ...
    async def get_realtime(self, symbol: str) -> float: ...

class CoinGeckoSource(DataSource):
    cg: Incomplete
    coin_map: Incomplete
    def __init__(self) -> None: ...
    def get_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame: ...
    async def get_realtime(self, symbol: str) -> float: ...

class FileSource(DataSource):
    file_path: Incomplete
    ext: Incomplete
    def __init__(self, file_path: str) -> None: ...
    def get_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame: ...
    async def get_realtime(self, symbol: str) -> float: ...

def validate_dataframe(df: pd.DataFrame, required_columns: list[str] | None = None) -> bool: ...
def normalize(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame: ...
def add_moving_average(df: pd.DataFrame, window: int = 14, price_col: str = 'Close') -> pd.DataFrame: ...
def add_rsi(df: pd.DataFrame, window: int = 14, price_col: str = 'Close') -> pd.DataFrame: ...

class MarketDataManager:
    config: Incomplete
    sources: Incomplete
    def __init__(self, config) -> None: ...
    def add_source(self, source: DataSource): ...
    def get_historical(self, symbol: str, start: str, end: str, source_name: str | None = None) -> pd.DataFrame: ...
    async def get_realtime(self, symbol: str, source_name: str | None = None) -> float: ...
    async def get_historical_batch(self, symbols: list[str], start: str, end: str, source_name: str | None = None) -> dict[str, pd.DataFrame]: ...
    async def stream_realtime(self, symbol: str, source_name: str | None = None, interval: int = 60): ...

def cached_historical(manager, symbol: str, start: str, end: str, source_name: str | None = None): ...

HAVE_CUDF: bool
