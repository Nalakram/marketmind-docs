import polars as pl
from typing import Any as Incomplete
from dataclasses import dataclass
from pathlib import Path
from srcPy.data.market_data import MarketDataManager as MarketDataManager
from srcPy.ops.caching import EnhancedCacheManager as EnhancedCacheManager, PersistentCache as PersistentCache, hash_config as hash_config, hash_dataframe_deterministic as hash_dataframe_deterministic, versioned_key as versioned_key
from srcPy.ops.multi_tier_cache import MultiTierClient as MultiTierClient
from srcPy.ops.observability import get_metrics as get_metrics, get_tracing as get_tracing, init_observability as init_observability, instrument as instrument, register_cache_hit_rate_gauges_for as register_cache_hit_rate_gauges_for
from srcPy.pipeline.core import AsyncMLflowLogger as AsyncMLflowLogger, PipelineContext as PipelineContext, PipelineStep as PipelineStep, StepRegistry as StepRegistry
from srcPy.pipeline.core.pipeline_core_builder import PipelineBuilder as PipelineBuilder, choose_combo as choose_combo, topo_order as topo_order
from srcPy.pipeline.execution import BatchPipeline as BatchPipeline
from srcPy.pipeline.pipeline_config import load_config as load_config
from srcPy.utils.dataframe_helpers import infer_ticker_col as infer_ticker_col, to_polars as to_polars
from srcPy.utils.dependency_manager import deps as deps
from srcPy.utils.exceptions import ConfigValidationError as ConfigValidationError, DataFetchError as DataFetchError
from typing import Any, Callable, Iterable, Mapping

pd: Incomplete
pl: Incomplete
dd: Incomplete
np: Incomplete
yaml: Incomplete
pynvml: Incomplete
psutil: Incomplete
BackendLiteral: Incomplete

class _OrchestrationCache:
    """orchestration cache class."""
    def __init__(self) -> None: ...
    def exists(self, key: str) -> bool: ...
    def save_npz(self, key: str, data: Any) -> None: ...
    def load_npz(self, key: str) -> Any | None: ...
    def save_json(self, key: str, data: Any) -> None: ...
    def load_json(self, key: str) -> Any | None: ...
    def save_df(self, key: str, df, **kwargs) -> None: ...
    def load_df(self, key: str, **kwargs): ...

def expand_grid(base: Mapping[str, Iterable[Any]], constraints: list[Callable[[dict[str, Any]], bool]] | None | None = None): ...
def stage(name: str | None = None, timeout_s: int | None = None): ...

class DataFrameAdapter:
    """Adapter for data frame interface."""
    df: Incomplete
    is_polars: Incomplete
    is_pandas: Incomplete
    def __init__(self, df) -> None: ...
    @property
    def shape(self): ...
    @property
    def columns(self): ...
    def hash(self): ...

class ConfigProxy:
    """config proxy class."""
    def __init__(self, data) -> None: ...
    def __getattr__(self, key): ...
    def get(self, path, default=None): ...

class BackendManager:
    """Manages backend resources and operations."""
    HAS_POLARS: Incomplete
    HAS_PANDAS: Incomplete
    HAS_DASK: Incomplete
    @classmethod
    def require_polars(cls) -> None: ...

class Evolver:
    """evolver class."""
    cache: Incomplete
    version_tag: Incomplete
    code_id: Incomplete
    def __init__(self, cache, version_tag, code_id) -> None: ...
    def load(self, context_hash): ...
    def save(self, context_hash, trials): ...
    def shrink_grid(self, grid, prior_trials, quantile: float = 0.4): ...

logger: Incomplete
run_cfg: Incomplete

class DataPrepError(Exception): ...
class ConfigError(DataPrepError): ...
class DataValidationError(DataPrepError): ...

@dataclass(frozen=True)
class OrchestratorConfig:
    """Configuration for orchestrator."""
    per_symbol_parallelism: int | str = ...
    gpu_slots: int | str = ...
    lazy: bool = ...
    date_chunk_size: str | None = ...
    cache_version_tag: str = ...
    cache_checkpoints: bool = ...
    search_mode: str = ...
    n_trials: int = ...
    metric_name: str = ...

class DataPrepOrchestrator:
    """data prep orchestrator class."""
    run_id: str | None
    cfg: dict[str, Any]
    run_cfg: dict[str, Any]
    run_cfg_raw: dict[str, Any]
    code_id: str | None
    ocfg: OrchestratorConfig
    cache: Any
    backtest_metric: Callable[[Any, Any, Mapping[str, Any], Mapping[str, Any]], float] | None
    expected_columns: Incomplete
    def __init__(self, run_cfg: Mapping[str, Any] | Any, cache: Any = None, backtest_metric: Callable[[Any, Any, Mapping[str, Any], Mapping[str, Any]], float] | None = None, entry_point_groups: list[tuple[str, str]] | None = None) -> None: ...
    def run(self) -> pd.DataFrame | pl.DataFrame | dict[str, Any]: ...
    def preprocess_multi_symbol(self, clean_df: pl.DataFrame | pd.DataFrame, preset: Mapping[str, Any], params: Mapping[str, Any]) -> dict[str, tuple[Any, Any, Mapping[str, Any]]]: ...
    def adaptive_map(self, fn, items, kind: str = 'auto', max_workers: int | None = None): ...

def run_dataprep(run_cfg: Mapping[str, Any] | Any, backtest_metric: Callable[[Any, Any, Mapping[str, Any], Mapping[str, Any]], float] | None = None): ...
def run_dataprep_from_path(run_cfg_path: str | Path, backtest_metric: Callable[[Any, Any, Mapping[str, Any], Mapping[str, Any]], float]) -> dict[str, Any]: ...

class Cache:
    """cache class."""
    def save_df(self, key: str, df) -> None: ...