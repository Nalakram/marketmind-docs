import numpy as np
from _typeshed import Incomplete
from dataclasses import dataclass
from srcPy.utils.optional_imports import pl
from typing import Any, AsyncIterator, Final, Sequence

__all__ = ['_SENTINEL', 'StreamingIsolationForest', 'StreamingPipeline', 'StreamingCleanerPipeline']

class _Sentinel: ...

_SENTINEL: Final[Incomplete]

class StreamingIsolationForest:
    contamination: Incomplete
    refit_every: Incomplete
    window_size: Incomplete
    def __init__(self, contamination: float = 0.1, refit_every: int = 100, window_size: int = 500) -> None: ...
    @property
    def buffer(self): ...
    @buffer.setter
    def buffer(self, value) -> None: ...
    @property
    def counter(self): ...
    @counter.setter
    def counter(self, value) -> None: ...
    @property
    def model(self): ...
    @model.setter
    def model(self, value) -> None: ...
    def predict(self, X: pl.DataFrame | np.ndarray | Sequence[float] | Sequence[Sequence[float]]) -> np.ndarray: ...

@dataclass
class _Config:
    engine: str = ...
    queue_size: int = ...
    batch_size: int = ...
    batch_timeout_s: float = ...

class StreamingPipeline:
    steps: Incomplete
    config: Incomplete
    def __init__(self, steps: Sequence[Any], config: dict[str, Any] | None = None) -> None: ...
    async def run(self, data_stream: AsyncIterator[Any], context: Any) -> AsyncIterator[Any]: ...

class StreamingCleanerPipeline(StreamingPipeline):
    enable_anomaly: Incomplete
    anomaly_detector: StreamingIsolationForest | None
    incremental_steps: list[Any]
    def __init__(self, steps: Sequence[Any], config: dict[str, Any] | None = None) -> None: ...
